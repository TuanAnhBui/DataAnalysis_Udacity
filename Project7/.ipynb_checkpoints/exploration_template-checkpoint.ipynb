{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid19 Exploratory Analysis\n",
    "## by Tuan Bui\n",
    "\n",
    "## Preliminary Wrangling\n",
    "\n",
    "> This is the dataset for the 2019 Novel Coronavirus operated by the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). The COVID19 dataset can be downloaded from the link https://github.com/CSSEGISandData/COVID-19\n",
    "\n",
    "> Additional information about countries and continents is downloaded from the link https://www.kaggle.com/statchaitya/country-to-continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import os\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load in your dataset and describe its properties through the questions below.\n",
    "Try and motivate your exploration goals through this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = \"csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "df = pd.DataFrame()\n",
    "features = ['Province_State',\n",
    " 'Country_Region',\n",
    " 'Last_Update',\n",
    " 'Confirmed',\n",
    " 'Deaths',\n",
    " 'Recovered',\n",
    " 'FIPS',\n",
    " 'Admin2',\n",
    " 'Latitude',\n",
    " 'Longitude',\n",
    " 'Active',\n",
    " 'Combined_Key']\n",
    "duplicated_names = {'Bahamas, The':'Bahamas',\n",
    "               'Mainland China':'China',\n",
    "               'Czechia':'Czech Republic', \n",
    "               'Dominican Republic':'Dominica',\n",
    "               'Gambia, The':'Gambia',\n",
    "               'Hong Kong SAR':'Hong Kong',\n",
    "               'Iran (Islamic Republic of)':'Iran',\n",
    "               'Korea, South':'South Korea',\n",
    "                'Republic of Korea':'South Korea',\n",
    "               'Republic of Ireland':'Ireland',\n",
    "               'Macau SAR': 'Macao', \n",
    "                'Macao SAR':'Macao',\n",
    "                    'Macau':'Macao',\n",
    "                'Republic of Moldova':'Moldova',\n",
    "                'Republic of the Congo':'Congo',\n",
    "                'Congo (Brazzaville)':'Congo',\n",
    "                'Congo (Kinshasa)':'Congo',\n",
    "                'Russian Federation':'Russia',\n",
    "                'St. Martin':'Saint Martin',\n",
    "                'The Bahamas':'Bahamas',\n",
    "                'The Gambia':'Gambia',\n",
    "                'Taiwan*':'Taiwan',\n",
    "                'United Kingdom':'UK',\n",
    "                'Viet Nam':'Vietnam'\n",
    "                   }\n",
    "count = 0\n",
    "for one_day in sorted(glob.glob(folder+'*.csv')):\n",
    "    one_day_df = pd.read_csv(str(one_day))\n",
    "    cols = one_day_df.columns\n",
    "    for col in cols:\n",
    "        if col.find(\"Province/State\")>=0:\n",
    "            one_day_df.rename(columns = {col:\"Province_State\"},inplace=True)\n",
    "        elif col.find(\"Country/Region\")>=0:\n",
    "            one_day_df.rename(columns = {col:\"Country_Region\"},inplace=True)\n",
    "        elif col.find(\"Last Update\")>=0:\n",
    "            one_day_df.rename(columns = {col:\"Last_Update\"},inplace=True)\n",
    "        elif col.find(\"Lat\")>=0:\n",
    "            one_day_df.rename(columns = {col:\"Latitude\"},inplace=True)\n",
    "        elif col.find(\"Long\")>=0:\n",
    "            one_day_df.rename(columns = {col:\"Longitude\"},inplace=True)       \n",
    "    for feature in features:\n",
    "        if not feature in one_day_df.columns:\n",
    "            one_day_df[feature] = np.NaN\n",
    "#    one_day_df.Province_State.fillna(\"\",inplace=True)\n",
    "    one_day_df['Country_Region'] = one_day_df['Country_Region'].replace(to_replace = duplicated_names)\n",
    "    one_day_df['Province'] = one_day_df.apply(lambda x: x.Country_Region+'/'+x.Province_State if not pd.isnull(x.Province_State) else x.Country_Region,axis=1)\n",
    "    \n",
    "    one_day_df.Last_Update = pd.to_datetime(one_day_df.Last_Update,dayfirst=False).dt.date\n",
    "    one_day_df = one_day_df.groupby(['Last_Update','Country_Region','Province']).agg({'Latitude':'mean','Longitude':'mean',\n",
    "                                             'Confirmed':'sum','Deaths':'sum','Recovered':'sum',\n",
    "                                              'Active':'sum'}).reset_index()\n",
    "    df = pd.concat([df,one_day_df], axis=0, ignore_index=True,sort=False)\n",
    "\n",
    "df.set_index('Province',inplace=True)\n",
    "df = df[~(df.Latitude==0)]\n",
    "\n",
    "lat_lng = df.groupby('Province').agg({'Latitude':'max','Longitude':'max'}).reset_index()\n",
    "lat_lng.set_index('Province',inplace=True)\n",
    "df.update(lat_lng)\n",
    "df.reset_index(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "change_names = {'Korea':'South Korea',\n",
    "               'United States of America':'US',\n",
    "                'Russian Federation':'Russia',\n",
    "                'United Kingdom of Great Britain and Northern Ireland':'UK',\n",
    "                'Macedonia':'North Macedonia',\n",
    "                'Brunei Darussalam':'Brunei',\n",
    "                '''Lao People's Democratic Republic''':'Laos',\n",
    "                'Syrian Arab Republic':'Syria',\n",
    "                'Timor-Leste':'East Timor'\n",
    "               }\n",
    "continents = pd.read_csv('countryContinent.csv',encoding = \"ISO-8859-1\")\n",
    "continents = continents[['country','continent']]\n",
    "continents.rename(columns={'country':'Country_Region','continent':'Continent'},inplace=True)\n",
    "continents.Country_Region = continents.Country_Region.apply(lambda x: x.split('(')[0].strip())\n",
    "continents.Country_Region = continents.Country_Region.apply(lambda x: x.split(',')[0].strip())\n",
    "continents['Country_Region'] = continents['Country_Region'].replace(to_replace = change_names)\n",
    "\n",
    "df = pd.merge(df,continents,how='left',on = 'Country_Region')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.to_csv(\"covid19\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24632 entries, 0 to 24964\n",
      "Data columns (total 10 columns):\n",
      "Province          24632 non-null object\n",
      "Last_Update       24632 non-null object\n",
      "Country_Region    24632 non-null object\n",
      "Latitude          24632 non-null float64\n",
      "Longitude         24632 non-null float64\n",
      "Confirmed         24632 non-null float64\n",
      "Deaths            24632 non-null float64\n",
      "Recovered         24632 non-null float64\n",
      "Active            24632 non-null float64\n",
      "Continent         24632 non-null object\n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Province', 'Last_Update', 'Country_Region', 'Latitude', 'Longitude',\n",
       "       'Confirmed', 'Deaths', 'Recovered', 'Active', 'Continent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the structure of your dataset?\n",
    "\n",
    "> The dataset has 24632 observations with 10 features.\n",
    "\n",
    "> - the features are :'Province', 'Last_Update', 'Country_Region', 'Latitude', 'Longitude', 'Confirmed', 'Deaths', 'Recovered', 'Active'. \n",
    "> - four features 'Province', 'Last_Update', 'Country_Region' and 'Continent' are in string datatype and,\n",
    "> - the others in numerical datatypes.\n",
    "\n",
    "### What is/are the main feature(s) of interest in your dataset?\n",
    "\n",
    "> Our main features of interest are: 'Confirmed', 'Deaths'.\n",
    "\n",
    "### What features in the dataset do you think will help support your investigation into your feature(s) of interest?\n",
    "\n",
    "> All other features will help support our investigation into our features of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Exploration\n",
    "\n",
    "> In this section, investigate distributions of individual variables. If\n",
    "you see unusual points or outliers, take a deeper look to clean things up\n",
    "and prepare yourself to look at relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute 'lineplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-641f049c1e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mglobal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Last_Update'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Confirmed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Last_Update'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Confirmed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'seaborn' has no attribute 'lineplot'"
     ]
    }
   ],
   "source": [
    "global_df = df.groupby('Last_Update')['Confirmed'].sum().reset_index()\n",
    "sb.lineplot(data=global_df,x='Last_Update',y='Confirmed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make sure that, after every plot or related series of plots, that you\n",
    "include a Markdown cell with comments about what you observed, and what\n",
    "you plan on investigating next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss the distribution(s) of your variable(s) of interest. Were there any unusual points? Did you need to perform any transformations?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Exploration\n",
    "\n",
    "> In this section, investigate relationships between pairs of variables in your\n",
    "data. Make sure the variables that you cover here have been introduced in some\n",
    "fashion in the previous section (univariate exploration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Exploration\n",
    "\n",
    "> Create plots of three or more variables to investigate your data even\n",
    "further. Make sure that your investigations are justified, and follow from\n",
    "your work in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Were there any interesting or surprising interactions between features?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At the end of your report, make sure that you export the notebook as an\n",
    "html file from the `File > Download as... > HTML` menu. Make sure you keep\n",
    "track of where the exported file goes, so you can put it in the same folder\n",
    "as this notebook for project submission. Also, make sure you remove all of\n",
    "the quote-formatted guide notes like this one before you finish your report!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
